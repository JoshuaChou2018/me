<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>Federated Learning - Tag - ğ…4h Group</title>
        <link>https://www.joshuachou.ink/tags/federated-learning/</link>
        <description>Federated Learning - Tag - ğ…4h Group</description>
        <generator>Hugo -- gohugo.io</generator><language>en</language><copyright>This work is licensed under a Creative Commons Attribution-NonCommercial 4.0 International License.</copyright><lastBuildDate>Sat, 05 Feb 2022 00:00:00 &#43;0000</lastBuildDate><atom:link href="https://www.joshuachou.ink/tags/federated-learning/" rel="self" type="application/rss+xml" /><item>
    <title>[NeurIPS] Personalized Federated Learning: A Meta-Learning Approachè§£è¯»</title>
    <link>https://www.joshuachou.ink/neurips-personalized-federated-learning-a-meta-learning-approach/</link>
    <pubDate>Sat, 05 Feb 2022 00:00:00 &#43;0000</pubDate>
    <author>Author</author>
    <guid>https://www.joshuachou.ink/neurips-personalized-federated-learning-a-meta-learning-approach/</guid>
    <description><![CDATA[<p><strong>Title:</strong> Personalized Federated Learning: A Meta-Learning Approach</p>
<p><strong>INFO:</strong> 34th Conference on Neural Information Processing Systems (NeurIPS 2020)</p>
<h6 id="ç ”ç©¶èƒŒæ™¯">ç ”ç©¶èƒŒæ™¯</h6>
<p>ç›®å‰çš„è”é‚¦å­¦ä¹ æ¡†æ¶æ˜¯åŸºäºæ‰€æœ‰usersçš„æ•°æ®ï¼Œæ•´åˆè®­ç»ƒå‡ºä¸€ä¸ªæœ€ä¼˜çš„serveræ¨¡å‹ã€‚</p>
<blockquote>
<p>However, this scheme only develops a common output for all the users, and, therefore, it does not adapt the model to each user.</p>
</blockquote>
<p>ä½†æ˜¯ï¼Œè¿™æ ·è®­ç»ƒå¤„æ¥çš„serveræ¨¡å‹ä¸ä¸€å®šé€‚ç”¨äºæ¯ä¸€ä¸ªuserï¼Œå°¤å…¶åœ¨ä¸åŒçš„usersæ‰€ç‹¬æœ‰çš„æ•°æ®å·®å¼‚æ¯”è¾ƒå¤§çš„æ—¶å€™ã€‚</p>
<blockquote>
<p>This is an important missing feature, especially given the heterogeneity of the underlying data distribution for various users.</p>
</blockquote>
<p>åœ¨heterogeneousçš„æƒ…æ™¯ä¸‹ï¼Œä½¿ç”¨federated averagingæ–¹æ³•è®­ç»ƒå‡ºæ¥çš„æ¨¡å‹å¯èƒ½åœ¨æ¯ä¸ªç‹¬ç«‹userä¸Šçš„è¡¨ç°ä¼šæ¯”è¾ƒå·®ã€‚</p>
<blockquote>
<p>In particular, in the heterogeneous settings where the underlying data distribution of users are not identical, the resulted global model obtained by minimizing the average loss could perform arbitrarily poorly once applied to the local dataset of each user.</p>]]></description>
</item><item>
    <title>[IEEE] Personalized Federated Learning WithDifferential Privacyè§£è¯»</title>
    <link>https://www.joshuachou.ink/ieee-personalized-federated-learning-with-differential-privacy/</link>
    <pubDate>Fri, 04 Feb 2022 00:00:00 &#43;0000</pubDate>
    <author>Author</author>
    <guid>https://www.joshuachou.ink/ieee-personalized-federated-learning-with-differential-privacy/</guid>
    <description><![CDATA[<p><strong>Title:</strong> Personalized Federated Learning With Differential Privacy</p>
<p><strong>DOI:</strong> 10.1109/JIOT.2020.2991416</p>
<p><strong>INFO:</strong> IEEE INTERNET OF THINGS JOURNAL, VOL. 7, NO. 10, OCTOBER 2020</p>
<p><strong>å‘è¡¨å‘¨æœŸ</strong>: Manuscript received December 15, 2019; revised March 20, 2020; accepted April  13,  2020.  Date of publication April 30, 2020;</p>]]></description>
</item></channel>
</rss>
