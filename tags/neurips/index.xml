<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>NeurIPS - Tag - ğ…4h Group</title>
        <link>https://www.joshuachou.ink/tags/neurips/</link>
        <description>NeurIPS - Tag - ğ…4h Group</description>
        <generator>Hugo -- gohugo.io</generator><language>en</language><copyright>This work is licensed under a Creative Commons Attribution-NonCommercial 4.0 International License.</copyright><lastBuildDate>Sat, 05 Feb 2022 00:00:00 &#43;0000</lastBuildDate><atom:link href="https://www.joshuachou.ink/tags/neurips/" rel="self" type="application/rss+xml" /><item>
    <title>[NeurIPS] Personalized Federated Learning: A Meta-Learning Approachè§£è¯»</title>
    <link>https://www.joshuachou.ink/neurips-personalized-federated-learning-a-meta-learning-approach/</link>
    <pubDate>Sat, 05 Feb 2022 00:00:00 &#43;0000</pubDate>
    <author>Author</author>
    <guid>https://www.joshuachou.ink/neurips-personalized-federated-learning-a-meta-learning-approach/</guid>
    <description><![CDATA[<p><strong>Title:</strong> Personalized Federated Learning: A Meta-Learning Approach</p>
<p><strong>INFO:</strong> 34th Conference on Neural Information Processing Systems (NeurIPS 2020)</p>
<h6 id="ç ”ç©¶èƒŒæ™¯">ç ”ç©¶èƒŒæ™¯</h6>
<p>ç›®å‰çš„è”é‚¦å­¦ä¹ æ¡†æ¶æ˜¯åŸºäºæ‰€æœ‰usersçš„æ•°æ®ï¼Œæ•´åˆè®­ç»ƒå‡ºä¸€ä¸ªæœ€ä¼˜çš„serveræ¨¡å‹ã€‚</p>
<blockquote>
<p>However, this scheme only develops a common output for all the users, and, therefore, it does not adapt the model to each user.</p>
</blockquote>
<p>ä½†æ˜¯ï¼Œè¿™æ ·è®­ç»ƒå¤„æ¥çš„serveræ¨¡å‹ä¸ä¸€å®šé€‚ç”¨äºæ¯ä¸€ä¸ªuserï¼Œå°¤å…¶åœ¨ä¸åŒçš„usersæ‰€ç‹¬æœ‰çš„æ•°æ®å·®å¼‚æ¯”è¾ƒå¤§çš„æ—¶å€™ã€‚</p>
<blockquote>
<p>This is an important missing feature, especially given the heterogeneity of the underlying data distribution for various users.</p>
</blockquote>
<p>åœ¨heterogeneousçš„æƒ…æ™¯ä¸‹ï¼Œä½¿ç”¨federated averagingæ–¹æ³•è®­ç»ƒå‡ºæ¥çš„æ¨¡å‹å¯èƒ½åœ¨æ¯ä¸ªç‹¬ç«‹userä¸Šçš„è¡¨ç°ä¼šæ¯”è¾ƒå·®ã€‚</p>
<blockquote>
<p>In particular, in the heterogeneous settings where the underlying data distribution of users are not identical, the resulted global model obtained by minimizing the average loss could perform arbitrarily poorly once applied to the local dataset of each user.</p>]]></description>
</item></channel>
</rss>
